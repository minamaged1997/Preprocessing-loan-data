{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daaf8d20",
   "metadata": {},
   "source": [
    " I am using loan Data ( Dummy Data ) in this project. I am using Numy libirary in Python to clean and preprocess it so that its more applicable for further invistigation using machine learning models.\n",
    "    \n",
    "Data used in this project : https://drive.google.com/file/d/12uCRK5bLa70rbSYcogaGypbsyz7u5DMB/view?usp=sharing\n",
    "<hr style=\"border:5px solid #108999\"> </hr>\n",
    "\n",
    "# importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f818e",
   "metadata": {},
   "source": [
    "The first step is to insert the CSV file and specify the delimiter ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3067928",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data=np.genfromtxt('D:\\Data Processing with Numpy\\\\loan-data.csv', delimiter=';')\n",
    "loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6dff9",
   "metadata": {},
   "source": [
    "here we can see that there are alot of nan values which indicates that there are alot of non numeric values \n",
    "so the first step is to know the columns that entirely hold strings and we can do that using 'nanmean()' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2547aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=np.nanmean(loan_data, axis=0)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c9bcb",
   "metadata": {},
   "source": [
    "using the next two code lines we can separate the numeric and non-numeric columns indixes in different two arrays (string_columns, numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d71ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns=np.argwhere(np.isnan(temp)).squeeze()\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26634336",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns=np.argwhere(np.isnan(temp)==False).squeeze()\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b2637",
   "metadata": {},
   "source": [
    "now, we can import the CSV file into four different numpy arrays header numeric, header string, data numerica and data string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14bdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric=np.genfromtxt('D:\\Data Processing with Numpy\\\\loan-data.csv',\n",
    "                                delimiter=';',\n",
    "                               usecols=numeric_columns,\n",
    "                               skip_header=1)\n",
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff61a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string=np.genfromtxt('D:\\Data Processing with Numpy\\\\loan-data.csv',\n",
    "                                delimiter=';',\n",
    "                               usecols=string_columns,\n",
    "                               skip_header=1,\n",
    "                               dtype=str)\n",
    "loan_data_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_head_string=np.genfromtxt('D:\\Data Processing with Numpy\\\\loan-data.csv',\n",
    "                                delimiter=';',\n",
    "                               usecols=string_columns,\n",
    "                               skip_footer=loan_data_string.shape[0],\n",
    "                               dtype=str)\n",
    "loan_head_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51640c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_head_numeric=np.genfromtxt('D:\\Data Processing with Numpy\\\\loan-data.csv',\n",
    "                                delimiter=';',\n",
    "                               usecols=numeric_columns,\n",
    "                               skip_footer=loan_data_string.shape[0],\n",
    "                               dtype=str)\n",
    "loan_head_numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7825e",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid #108999\"> </hr> \n",
    "\n",
    "# String data Processing\n",
    "\n",
    "After separating our data without the headers into 2 arrays we will start working on them one at a time let's start with the string data which consists of columns: issue_d, loan_status, term, grade, sub_grade, verification_status, url and addr_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_string[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b44180",
   "metadata": {},
   "source": [
    "### Issue_date\n",
    "we checked the unique values of the first column in the string data array. as it's obvious, we can see that dates consists of days and months only also, all loans dates are in the same day but different month. so there is no use of mintioning the day\n",
    "and we can also replace the month name with its numerical value (1-12) and the missing values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string[:,0]=np.chararray.strip(loan_data_string[:,0],'-15')\n",
    "loan_data_string[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(months.shape[0]):\n",
    "    loan_data_string[:,0]=np.where(loan_data_string[:,0]==months[i],\n",
    "                                  i,\n",
    "                                  loan_data_string[:,0])\n",
    "np.unique(loan_data_string[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4694a",
   "metadata": {},
   "source": [
    "### loan_status\n",
    "we checked the unique values of the second column 'Loan_statuts' in the string data array. according to the business model we should catigorize these values into two groups (good '1', bad '0')\n",
    "\n",
    "ps: the Empty values ' ' means there were missing values in the CSV file so we assign them according to the worest case scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0dc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_string[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da821ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_bad = np.array(['','Charged Off','Default','Late (31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51474cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string[:,1]= np.where(np.isin(loan_data_string[:,1], status_bad),0,1)\n",
    "np.unique(loan_data_string[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee726ffa",
   "metadata": {},
   "source": [
    "### Term\n",
    "lets move to the third column 'term' which contains three unique values ('', '36 months','60 months').\n",
    "we will replace '36 months' with '36' , '60 months' with '60' and ' ' with '36' as it's the worest case scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72be0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_string[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad62ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string[:,2]=np.chararray.strip(loan_data_string[:,2], ' months')\n",
    "np.unique(loan_data_string[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcca28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string[:,2]=np.where(loan_data_string[:,2]=='',\n",
    "                              60,\n",
    "                              loan_data_string[:,2])\n",
    "np.unique(loan_data_string[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344f6c8",
   "metadata": {},
   "source": [
    "### grade and sub_grade\n",
    "in the next two columns (grade column, Sub-grade column),<br>\n",
    "the unique values for the grade column are (' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G').<br>\n",
    "and for the sub grade are the same like the grade but a numeric value from 1-5 is added after each grade.<br> so we can<br>\n",
    "1- Replace the missing values of sub-grade with the the least level of grade if found for example if the grade is 'B' so the missing sub grade is 'B5'. <br>2- delete the grade column as all its info is duplicated in sub-grade.<br>3- replace the missing subgrades with a newly added value 'H1'<br>4- replace every level of sub-grade with a numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_string[:,4], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90565d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Replace the missing values of sub-grade with the the least level of grade if found \n",
    "#    for example if the grade is 'B' so the missing sub grade is 'B5'.\n",
    "\n",
    "for i in range(loan_data_string.shape[0]):\n",
    "    loan_data_string[i,4]=np.where((loan_data_string[i,4]=='')&(loan_data_string[i,3]!=''),\n",
    "                                  loan_data_string[i,3]+'5',\n",
    "                                  loan_data_string[i,4])\n",
    "    \n",
    "np.unique(loan_data_string[:,4], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- delete the grade column as all its info is duplicated in sub-grade.\n",
    "\n",
    "loan_data_string=np.delete(loan_data_string, 3, axis=1)\n",
    "loan_data_string[:,3]\n",
    "loan_head_string=np.delete(loan_head_string, 3)\n",
    "loan_head_string[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- replace the missing subgrades with a newly added value 'H1'\n",
    "\n",
    "loan_data_string[:,3]=np.where(loan_data_string[:,3]=='',\n",
    "                              'H1',\n",
    "                              loan_data_string[:,3])\n",
    "\n",
    "np.unique(loan_data_string[:,3], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- replace every level of sub-grade with a numeric value\n",
    "\n",
    "keys= list(np.unique(loan_data_string[:,3]))\n",
    "values= list(range(1,np.unique(loan_data_string[:,3]).shape[0]+1))\n",
    "temp_dict=dict(zip(keys, values))\n",
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in temp_dict.keys():\n",
    "    loan_data_string[:,3]=np.where(loan_data_string[:,3]==i,\n",
    "                                  temp_dict[i],\n",
    "                                  loan_data_string[:,3])\n",
    "np.unique(loan_data_string[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a1033",
   "metadata": {},
   "source": [
    "### Verification Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75eb12d",
   "metadata": {},
   "source": [
    "for column 'verification_status', the unique values in this column are (' ',Not Verified, Sourece Verified, Verified)\n",
    "so we can process these data in the following steps:<br>1- replace values (' ',Not Verified) with 0<br>2- replace (Sourece Verified, Verified) with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded5be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(loan_data_string[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string[:,4]=np.where((loan_data_string[:,4]=='')|(loan_data_string[:,4]=='Not Verified'),\n",
    "                              0,1)\n",
    "np.unique(loan_data_string[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bbccbb",
   "metadata": {},
   "source": [
    "### URL\n",
    "for the column 'URL' we can see that all the values like this 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226' with except change in the id part at the end of the URL also we can see that this id at the end is the same as the id column in the numeric data<br>Then there is no need for this column as it doesn't add value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string[:5,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric[:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 5 rows from URL column \n",
    "loan_data_string=np.delete(loan_data_string, 5, axis=1)\n",
    "loan_head_string=np.delete(loan_head_string, 5)\n",
    "print(loan_head_string)\n",
    "print(loan_data_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e13fe3",
   "metadata": {},
   "source": [
    "### State Address\n",
    "for column State Address I renamed to be more understandable. The values in that columns is the abbreviations of all the states in United States plus some missing values so<br>1- the first thing to do is to replace the missing values with 0<br> when examining the number of records for each state I found out that every state separately does not give any insights as the the number of records are very low so <br>2- it would be better to divide them into 4 catigories (states_west, states_south, states_midwest, states_east)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_head_string[-1]='state_address'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0be476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- the first thing to do is to replace the missing values with 0\n",
    "loan_data_string[:,5] = np.where(loan_data_string[:,5] == '', \n",
    "                                  0, \n",
    "                                  loan_data_string[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b05cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_west = np.array(['WA', 'OR','CA','NV','ID','MT', 'WY','UT','CO', 'AZ','NM','HI','AK'])\n",
    "states_south = np.array(['TX','OK','AR','LA','MS','AL','TN','KY','FL','GA','SC','NC','VA','WV','MD','DE','DC'])\n",
    "states_midwest = np.array(['ND','SD','NE','KS','MN','IA','MO','WI','IL','IN','MI','OH'])\n",
    "states_east = np.array(['PA','NY','NJ','CT','MA','VT','NH','ME','RI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20eaa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- it would be better to divide them into 4 catigories (states_west, states_south, states_midwest, states_east)\n",
    "\n",
    "loan_data_string[:,-1] = np.where(np.isin(loan_data_string[:,-1], states_west), 1, loan_data_string[:,-1])\n",
    "loan_data_string[:,-1] = np.where(np.isin(loan_data_string[:,-1], states_south), 2, loan_data_string[:,-1])\n",
    "loan_data_string[:,-1] = np.where(np.isin(loan_data_string[:,-1], states_midwest), 3, loan_data_string[:,-1])\n",
    "loan_data_string[:,-1] = np.where(np.isin(loan_data_string[:,-1], states_east), 4, loan_data_string[:,-1])\n",
    "\n",
    "np.unique(loan_data_string[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e496267",
   "metadata": {},
   "source": [
    "### checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d06acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for i in loan_data_string.flatten():\n",
    "    if i=='':\n",
    "        counter+=1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b606cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string=loan_data_string.astype(int)\n",
    "loan_data_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515ea82",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid #108999\"> </hr> \n",
    "\n",
    "\n",
    "# Numeric data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d0b94",
   "metadata": {},
   "source": [
    "Now its time to process the numeric Data which is the cloumns ['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment',\n",
    "'total_pymnt']<br>through these following steps we can alter these columns so that we get an array with no missing values and ready for processing <br>1- replace missing values with vallues of the worest case scenario\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_head_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c3bed",
   "metadata": {},
   "source": [
    "### loan ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0269480",
   "metadata": {},
   "source": [
    "from this line we can see that the first column 'ID' doesnt have any missing values as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(loan_data_numeric[:,0]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea716be4",
   "metadata": {},
   "source": [
    "### Loan Amount, Installments, Total Payments \n",
    "PS: the worest case scenario is to replace the messing values for Loaned Amount, Interest Rate, Total Payment and Installment with the maximum of these columns and the minimum of funded amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "max=np.nanmax(loan_data_numeric[:,(1,3,4,5)], axis=0)\n",
    "np.nanmean(loan_data_numeric[:,[1,3,4,5]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for i in [1,3,4,5]:\n",
    "    loan_data_numeric[:,i]= np.where(np.isnan(loan_data_numeric[:,i]),\n",
    "                               max[counter],\n",
    "                               loan_data_numeric[:,i])\n",
    "    counter+=1\n",
    "np.nanmean(loan_data_numeric[:,[1,3,4,5]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display the interest rate as a decimal value \n",
    "loan_data_numeric[:,3]=loan_data_numeric[:,3]/100\n",
    "loan_data_numeric[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586879a6",
   "metadata": {},
   "source": [
    "### Funded Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(loan_data_numeric[:,2]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "min=np.nanmin(loan_data_numeric[:,2])\n",
    "np.nanmean(loan_data_numeric[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric[:,2]= np.where(np.isnan(loan_data_numeric[:,2]),\n",
    "                               min,\n",
    "                               loan_data_numeric[:,2])\n",
    "np.nanmean(loan_data_numeric[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9682f8b",
   "metadata": {},
   "source": [
    "### The Exchange Rate\n",
    "here I used another dataset for the exchange (EUR - USD) it consists of 12 rows for 12 months of the year 2015 in which this loan data is collected.<br>so we want to create another column that contains the exchange rates for each loan and attach it to loan_data_neumeric array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EUR_USD = np.genfromtxt(\"D:\\\\Data Processing with Numpy\\\\EUR-USD.csv\", delimiter = ',', autostrip = True, skip_header = 1, usecols = 3)\n",
    "EUR_USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_string[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exchange_rate = loan_data_string[:,0]\n",
    "\n",
    "for i in range(1,13):\n",
    "    exchange_rate = np.where(exchange_rate == i,\n",
    "                             EUR_USD[i-1],\n",
    "                             exchange_rate)    \n",
    "\n",
    "exchange_rate = np.where(exchange_rate == 0,\n",
    "                         np.mean(EUR_USD),\n",
    "                         exchange_rate)\n",
    "\n",
    "exchange_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e5f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a917891",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate=np.reshape(exchange_rate,(10000,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce84334",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric=np.hstack((loan_data_numeric,exchange_rate))\n",
    "loan_data_numeric[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf0802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_head_numeric=np.hstack((loan_head_numeric, np.array(['Exchange_Rate'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_head_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80886ea",
   "metadata": {},
   "source": [
    "### from USD to EUR\n",
    "here we want to change the numerical values in columns (Loan amount, Installments, total payments, fund Rates) from USD to EUR using the newly attached column (exchange rate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "EUR_amount=np.zeros((loan_data_numeric.shape[0],4))\n",
    "\n",
    "for i in [1,2,4,5]:\n",
    "    EUR_amount[:,counter]=loan_data_numeric[:,i]/loan_data_numeric[:,6]\n",
    "    counter+=1\n",
    "\n",
    "EUR_amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric=np.hstack((loan_data_numeric, EUR_amount))\n",
    "loan_data_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611446b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding EUR columns name to the header\n",
    "\n",
    "loan_head_numeric=np.hstack((loan_head_numeric,np.array([i+'_EUR' for i in loan_head_numeric[[1,2,4,5]]])))\n",
    "loan_head_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding _USD to the columns name to specify their currency\n",
    "\n",
    "for i in [1,2,4,5]:\n",
    "    loan_head_numeric[i]+='_USD'\n",
    "loan_head_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearranging the columns\n",
    "columns_index_order = [0,1,7,2,8,3,4,9,5,10,6]\n",
    "loan_data_numeric=loan_data_numeric[:,columns_index_order]\n",
    "loan_head_numeric=loan_head_numeric[columns_index_order]\n",
    "loan_head_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38522b6b",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid #108999\"> </hr> \n",
    "\n",
    "# Create the complete Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4070dede",
   "metadata": {},
   "source": [
    "what I will do here :<br>1- concatenate the headers (string, numeric)<br>2-concatenate the data columns<br>3- sort the records ascending depending on the id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- concatenate the headers (string, numeric)\n",
    "loan_header=np.hstack((loan_head_numeric, loan_head_string))\n",
    "loan_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43daac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-concatenate the data columns\n",
    "\n",
    "loan_data=np.hstack((loan_data_numeric, loan_data_string))\n",
    "loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- sort the records ascending depending on the id\n",
    "\n",
    "loan_data=loan_data[np.argsort(loan_data[:,0]),:]\n",
    "loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_header=loan_header.reshape((1,17))\n",
    "loan_header.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d54272",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_Final=np.vstack((loan_header, loan_data))\n",
    "loan_data_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc76ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"D:\\\\Data Processing with Numpy\\\\loan-data-preprocessed.csv\", \n",
    "           loan_data_Final, \n",
    "           fmt = '%s',\n",
    "           delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e981e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
